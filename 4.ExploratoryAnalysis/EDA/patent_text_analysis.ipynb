{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/jdk1.8.0_144\n",
      "Welcome to\n",
      "      ____              __\n",
      "     / __/__  ___ _____/ /__\n",
      "    _\\ \\/ _ \\/ _ `/ __/  '_/\n",
      "   /__ / .__/\\_,_/_/ /_/\\_\\   version 2.2.0\n",
      "      /_/\n",
      "\n",
      "Using Python version 2.7.3 (default, Feb 12 2013 14:01:46)\n",
      "SparkSession available as 'spark'.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "print os.environ['JAVA_HOME']\n",
    "#os.environ['PYSPARK_SUBMIT_ARGS'] = '--jars /data/spark-csv_2.11-1.5.0.jar'\n",
    "spark_home = os.environ['SPARK_HOME'] = '/root/spark15'\n",
    "if not spark_home:\n",
    "    raise ValueError('SPARK_HOME enviroment variable is not set')\n",
    "sys.path.insert(0,os.path.join(spark_home,'python'))\n",
    "sys.path.insert(0,os.path.join(spark_home,'python/lib/py4j-0.9-src.zip'))\n",
    "execfile(os.path.join(spark_home,'python/pyspark/shell.py'))\n",
    "sc.setLogLevel(\"WARN\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "del os.environ['PYSPARK_SUBMIT_ARGS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "fileout = sc.textFile(\"/user/root/w210/full_text/patent_claims_fulltext.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SQLContext\n",
    "sqlContext = SQLContext(sc)\n",
    "df = sqlContext.read.csv( path = \"/user/root/w210/full_text/patent_claims_fulltext.csv\",header = True,inferSchema = True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SPARK : Getting Data Schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- pat_no: integer (nullable = true)\n",
      " |-- claim_no: integer (nullable = true)\n",
      " |-- claim_txt: string (nullable = true)\n",
      " |-- dependencies: string (nullable = true)\n",
      " |-- ind_flg: integer (nullable = true)\n",
      " |-- appl_id: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's see Few sample claim_txt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(claim_txt=u'1. A golf glove comprising at least an index finger receptacle, a middle finger receptacle and a back surface extending from said receptacles in the direction of the wrist, and further comprising another finger receptacle disposed adjacent said index finger receptacle and said middle finger receptacle and overlapping a portion of said back section.'),\n",
       " Row(claim_txt=u\"4. A golf glove adapted for use on one hand of a golf player comprising at least an index finger receptacle and further comprising a finger receptacle attached to the side of said index finger receptacle most nearly adjacent to the thumb and adapted to receive a finger of the golf player's other hand.\"),\n",
       " Row(claim_txt=u'3. A glove comprising an index finger receptacle, a middle finger receptacle, a back surface extending in the direction of the wrist, a finger restraining strap extending between said receptacles, and a finger restraining strap attached to said back surface adjacent said index finger receptacle and said middle finger receptacle and aligned in a direction substantially parallel to said finger restraining strap extending between said finger receptacles.'),\n",
       " Row(claim_txt=u'2. A golf glove in accordance with claim 1 wherein said other finger receptacle is attached along its periphery to said index finger receptacle, said middle finger receptacle and said back surface.'),\n",
       " Row(claim_txt=u'1. In combination with a height adjustable crib or the like of the type having a corner post and an extensible leg slidably connected to the corner post and having a series of holes along its length, a lock comprisingA. a rigid bracket extending around the extensible leg and having sides lying flush against opposite sides of the corner post;B. means for pivotally connecting the bracket sides to the corner post so that the bracket can be swung toward and away from the leg;C. a rigid nose projecting from the bracket and extending toward the leg, said nose being arranged to engage in one of the leg holes when the bracket is swung against the leg so as to lock the leg at a selected position of lengthwise adjustment relative to the corner post, andD. means mounted on the corner post and cooperating with the bracket for removably retaining the bracket with its nose in said hole said retaining means comprising1. a latch pivotally connected to the corner post adjacent to the bracket, and a slot formed in a side of the bracket, the sides of the slot being engaged by the latch when the bracket is positioned with its nose in said hole.'),\n",
       " Row(claim_txt=u'3. The lock defined in claim 1 wherein the pivotal connection of the latch to the corner post is off center so that the force of gravity tends to maintain the latch in the slot when the bracket is positioned with its nose in said hole.'),\n",
       " Row(claim_txt=u'2. The lock defined in claim 1 wherein the bracket comprises a single rigid metal stamping.'),\n",
       " Row(claim_txt=u'21. A bed arrangement comprisinga bed frame,a side rail assembly for said bed frame, said side rail assembly comprisinga pair of separately detachable side rails each with spaced risers pivotally secured thereto, and one riser having a releasable pivot-prevention lock thereon,said risers being removably pivotally mounted on said bed frame,and a pair of nonpermanent and manually releasably detachable lateral rigidifying stabilizers cross members extending transversely across said bed frame and releasably engageable in pivotal and lateral rigidifying interconnecting relation each with respective opposite pairs of said side rail risers,said side rail risers each having pivot pins thereon,and said detachable stabilizer cross members each having end openings for receiving said pivot pins,said cross members being relatively pivotally engaged at their end openings with said riser pivot pins, and being supported in suspended relation between and by said pivot pins,and releasable securing means releasably securing said pivot pins to said bed frame with said cross members extending therebetween,said releasable securing means comprising finger-actuatable spring retainers for each of said risers and releasably engageable in resilient relation with said riser pins,said releasable pivot-prevention lock on said riser including a latch removably pivotally engaged with a respective adjacent effective portion of one of said longitudinal side frame members,two of said spring retainers being each secured in latch-engaging relation to a respective one of said riser pivot pins and being also releasably engageable with a said groove in the respective said pivot pin at a position spaced along the length of said pin from said wrap-engaging relation position of said spring retainer on the respective said pin.'),\n",
       " Row(claim_txt=u'20. A bed arrangement comprisinga bed frame,a side rail assembly for said bed frame, said side rail assembly comprisinga pair of separately detachable side rails each with spaced risers pivotally secured thereto,said risers being removably pivotally mounted on an effective portion of said bed frame,and a pair of nonpermanent and detachable cross members extending transversely across said bed frame and releasably engageable in pivotal interconnecting relation each with respective opposite pairs of said side rail risers,said side rail risers each having pivot pins thereon,and said cross members each having end openings for receiving said pivot pins,said cross members being relatively pivotally engaged at their end openings with said riser pivot pins, and being supported in suspended relation between and by said pivot pins,said bed frame including spaced generally parallel longitudinal side frame members with spaced holes effectively formed thereon,said cross members extending between said side frame members and having their said end openings in effective alignment with respective opposite pairs of said holes,said riser pivot pins extending through said holes and into said cross member end openings,and releasable securing means releasably securing said pins within said side frame member holes.'),\n",
       " Row(claim_txt=u'3. A bed arrangement according to claim 2,the pivotal engagement of said latches with said longitudinal side frame members being about a generally horizontal pivot axis, said one pivoted position of said latch being an upward pivoted position as compared to said second pivoted position of said latch, whereby said latch is gravity biased toward said one pivoted position.')]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.select(\"claim_txt\").head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get total number of records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "52192948"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the Summary statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[summary: string, pat_no: string, claim_no: string, claim_txt: string, dependencies: string, ind_flg: string, appl_id: string]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find Unique Patent Cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3537528"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.select('pat_no').distinct().count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find records with no NULL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41028838"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dropna().count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Average Length of claim Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import length\n",
    "\n",
    "dfnew = df.withColumn('length', length(\"claim_txt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(pat_no=3931035, sum(length)=710),\n",
       " Row(pat_no=3931157, sum(length)=3134),\n",
       " Row(pat_no=3931434, sum(length)=840),\n",
       " Row(pat_no=3931856, sum(length)=1615)]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfnew.groupby('pat_no').agg({'length': 'sum'}).head(4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndf = dfnew.groupby('pat_no').agg({'length': 'sum'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['pat_no', 'sum(length)']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ndf.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Maximum Length of claim text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+\n",
      "|max(sum(length))|\n",
      "+----------------+\n",
      "|          479210|\n",
      "+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import max\n",
    "ndf.select(max('sum(length)')).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Minimum Length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+\n",
      "|min(sum(length))|\n",
      "+----------------+\n",
      "|              11|\n",
      "+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import min\n",
    "ndf.select(min('sum(length)')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+\n",
      "| avg(sum(length))|\n",
      "+-----------------+\n",
      "|5660.391970042358|\n",
      "+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import mean\n",
    "ndf.select(mean('sum(length)')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
